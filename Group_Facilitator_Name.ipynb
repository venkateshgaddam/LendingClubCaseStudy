{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling, Cleaning and Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "# Initialize the DataFrame Object.\n",
    "file_path=\"loan.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "# The data.info() function shows us that some of the columns have missing values and some have incorrect data types associated with them.\n",
    "data.info()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of Nulls, Blanks in the dataset\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irrelvant Columns which should be dropped to make the dataset more manageable.\n",
    "# ==============================================================================\n",
    "#\n",
    "# Columns: id, member_d, url\n",
    "#\n",
    "# Reason: These are identifiers which are unrelated to business and are just generated by datastore used.\n",
    "#         They cannot be considered as variables for analysis.\n",
    "#\n",
    "data.drop(columns = ['id', 'member_id', 'url'], axis = 1, inplace = True)\n",
    "\n",
    "# Columns: pymnt_plan, initial_list_status, collections_12_mths_ex_med, mths_since_last_major_derog, policy_code,\n",
    "#          application_type, annual_inc_joint, dti_joint, verification_status_joint, acc_now_delinq, \n",
    "#          tot_coll_amt, tot_cur_bal, open_acc_6m, open_il_6m, open_il_12m, open_il_24m, mths_since_rcnt_il, \n",
    "#          total_bal_il, il_util, open_rv_12m, open_rv_24m, max_bal_bc, all_util, total_rev_hi_lim, inq_fi, \n",
    "#          total_cu_tl, inq_last_12m, acc_open_past_24mths, avg_cur_bal, bc_open_to_buy, bc_util, \n",
    "#          chargeoff_within_12_mths, delinq_amnt, mo_sin_old_il_acct, mo_sin_old_rev_tl_op, mo_sin_rcnt_rev_tl_op, \n",
    "#          mo_sin_rcnt_tl, mort_acc, mths_since_recent_bc, mths_since_recent_bc_dlq, mths_since_recent_inq, \n",
    "#          mths_since_recent_revol_delinq, num_accts_ever_120_pd, num_actv_bc_tl, num_actv_rev_tl, num_bc_sats, \n",
    "#          num_bc_tl, num_il_tl, num_op_rev_tl, num_rev_accts, num_rev_tl_bal_gt_0, num_sats, num_tl_120dpd_2m, \n",
    "#          num_tl_30dpd, num_tl_90g_dpd_24m, num_tl_op_past_12m, pct_tl_nvr_dlq, percent_bc_gt_75, tax_liens, \n",
    "#          tot_hi_cred_lim, total_bal_ex_mort, total_bc_limit, total_il_high_credit_limit\n",
    "#\n",
    "# Reason: There is only one/invalid value for all rows and cannot be considered as variable.\n",
    "#\n",
    "columns = ['pymnt_plan', 'initial_list_status', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'policy_code', 'application_type', 'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit']\n",
    "data.drop(columns = columns, axis = 1, inplace = True)\n",
    "\n",
    "# Columns: title\n",
    "#\n",
    "# Reason: This are no standardised values so cannot be grouped/aggegated.\n",
    "#\n",
    "data.drop(columns = ['title'], axis = 1, inplace = True)\n",
    "\n",
    "# Columns: recoveries, collection_recovery_fee\n",
    "#\n",
    "# Reason: These are system related fields.\n",
    "#\n",
    "data.drop(columns = ['recoveries', 'collection_recovery_fee'], axis = 1, inplace = True)\n",
    "\n",
    "# Columns: emp_title\n",
    "#\n",
    "# Reason: This has different set of values for the same title. E.g. \"7 Eleven\", \"7-eleven\", etc.\n",
    "#         These values can be corrected and standardized, but the insights gained will be at particular\n",
    "#         Customer level, and might not be that useful. So it can be dropped.\n",
    "#\n",
    "data.drop(columns = ['emp_title'], axis = 1, inplace = True)\n",
    "# NOTE: We will keep 'desc' column and convert it into boolean (desc provided or not) and derive insights.\n",
    "\n",
    "# Columns: funded_amnt, funded_amnt_inv\n",
    "#\n",
    "# Reason: They have almost similar data as loan_amnt\n",
    "#data.drop(columns = ['funded_amnt_inv'], axis = 1, inplace = True)\n",
    "\n",
    "# Columns: total_pymnt_inv, total_rec_prncp\n",
    "#\n",
    "# Reason: They have almost similar data as total_pymnt\n",
    "data.drop(columns = ['total_pymnt_inv', 'total_rec_prncp'], axis = 1, inplace = True)\n",
    "\n",
    "# Columns: delinq_2yrs, out_prncp, out_prncp_inv, total_pymnt\n",
    "#\n",
    "# Reason: These columns show data only after the charge off has already happened. So they won't generate\n",
    "#         any useful insight in determining defaulters.\n",
    "data.drop(columns = ['delinq_2yrs', 'out_prncp', 'out_prncp_inv'], axis = 1, inplace = True)\n",
    "\n",
    "# Columns: next_pymnt_d, revol_bal, total_pymnt, total_rec_int\n",
    "#          last_pymnt_d, last_pymnt_amnt, last_credit_pull_d\n",
    "#\n",
    "# Reason: These columns are not directly related to determining a default.\n",
    "data.drop(columns = ['next_pymnt_d', 'revol_bal', 'total_pymnt', 'total_rec_int', 'last_pymnt_d', 'last_pymnt_amnt', 'last_credit_pull_d'], axis = 1, inplace = True)\n",
    "# NOTE: We will keep 'total_rec_late_fee' and convert it into a boolean (late payments done/not done) and compare\n",
    "#       whether late payers charge off and derive other insights from it.\n",
    "\n",
    "# print remaining columns\n",
    "#\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * data.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to be removed based on the above condition:\n",
    "#\n",
    "columns = ['mths_since_last_delinq', 'mths_since_last_record']\n",
    "data = data.drop(columns, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_rows = len(data)\n",
    "\n",
    "# The rows where loan_stats=Current are the data where the loan repayment is currently in progress\n",
    "# The loans which are currently in progress will not contribute to decisions \n",
    "# of default or pass as it's difficult to predict the outcome\n",
    "#\n",
    "# Dropping the rwos early as, dropping all Currrent rows introduces NA columns which can be easily dropped\n",
    "data = data[data['loan_status'] != \"Current\"]\n",
    "\n",
    "print(data.shape)\n",
    "# Print current data statistics after dropping rows with loan_status \"CURRENT\"\n",
    "curr_rows = len(data)\n",
    "print(\"Before: \" + str(prev_rows))\n",
    "print(\"Number of rows dropped where loan_status = 'Current':\", (prev_rows - curr_rows))\n",
    "print(\"After: \" + str(curr_rows))\n",
    "print(\"Percentage of rows dropped = \", round((prev_rows - curr_rows)/prev_rows*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical/strict interger columns, remove rows with less than 4% missing values.\n",
    "#\n",
    "categorical_columns = ['pub_rec_bankruptcies']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    data = data.dropna(subset = [col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping text/description columns which wont contribute to overall analysis\n",
    "# These are names of establishment etc which will not contribute to loan pass or failure.\n",
    "data = data.drop(['desc'],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping column sub_grade as the current analysis will limit to Grade only\n",
    "data = data.drop(['sub_grade'],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns whose all the values are NA.\n",
    "print(\"Total columns with values NA: \", len(data.columns[data.isna().all()].tolist()),\"\\n\\n\")\n",
    "print(\"Columns with all values as NA\\n\", data.columns[data.isna().all()].tolist())\n",
    "\n",
    "# Dropping all the columns whose all the records are NaN or Null\n",
    "data = data.dropna(axis='columns', how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns with all zero values\n",
    "data = data.loc[:, (data != 0).any(axis=0)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the columns loan_amnt and funded_amnt as flot64\n",
    "data = data.astype({'loan_amnt':'float','funded_amnt':'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the term column into an integer from a string\n",
    "data['term'] = data['term'].apply(lambda x : int(x[:-7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert int_rate to  float by removing the \"%\" character\n",
    "data['int_rate'] = data['int_rate'].apply(lambda x : float(x[:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round off the values of key float fields to 2 decimal place\n",
    "# all int_rate and dti already limited to 2 edcimal\n",
    "print(\"Rounding columns to 2 decimal places\")\n",
    "for c in ['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'int_rate', 'dti']:\n",
    "    print(c)\n",
    "    data[c] = data[c].apply(lambda x: round(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the loan_status to boolean column. \"Fully-Paid is True and Charged Off is False\"\n",
    "# Added a function instead of lambda because, if this is accidentally re-run on a boolean column, the logic broke\n",
    "# Now it will only convert to boolean if the column is a string and has the two specific values\n",
    "# def convert_loan_status_to_boolean(x):\n",
    "#     if x == \"Fully Paid\":\n",
    "#         return True\n",
    "#     elif x == \"Charged Off\":\n",
    "#         return False\n",
    "#     else:\n",
    "#         return x\n",
    "\n",
    "# data['loan_status'] = data['loan_status'].apply(lambda x: convert_loan_status_to_boolean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting emp_length to integer values\n",
    "# Converting emp_length as numerical data to create more effective statistical analysis as compared to nominal values\n",
    "data['emp_length'] = data['emp_length'].replace({'< 1 year': 0, '2 years': 2, '3 years': 3, \n",
    "                                                         '7 years': 7, '4 years': 4, '5 years': 5, \n",
    "                                                         '1 year': 1, '6 years': 6, '8 years': 8, \n",
    "                                                         '9 years': 9,  '10+ years': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if blanks exist\n",
    "data['emp_length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the current dimensions of the dataframe\n",
    "rows_before = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with empty values in this scenario\n",
    "# Since the percent of rows is very small, dropping the rows instead of imputing them\n",
    "data = data[data['emp_length'].notna()]\n",
    "data = data[data['pub_rec_bankruptcies'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dimensions of the dataframe after dropping rows\n",
    "rows_after = len(data)\n",
    "print(\"Number of rows dropped = ,\", (rows_before - rows_after))\n",
    "print(\"Percentage of rows dropped = \", round((rows_before - rows_after)/rows_before*100,2),\"%\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['total_rec_late_fee', 'revol_util']\n",
    "\n",
    "for col in columns:\n",
    "    data[columns] = data[columns].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for possible columns with outliers\n",
    "#\n",
    "numerical_cols = [\n",
    "    'loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti', 'revol_util', 'open_acc', 'total_acc'\n",
    "]\n",
    "\n",
    "for col in numerical_cols:\n",
    "    sns.boxplot(x = data[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above charts we identify the following columns with squeezed distribution due to outliers.\n",
    "# Calculate SD \n",
    "#Remove values which are away from mean by 2 times SD.\n",
    "\n",
    "columns = ['loan_amnt', 'int_rate', 'installment', 'annual_inc', 'open_acc', 'total_acc']\n",
    "\n",
    "Q1 = data[columns].quantile(0.25)\n",
    "Q3 = data[columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(Q1)\n",
    "print(Q3)\n",
    "\n",
    "original_len = data.shape[0]\n",
    "data = data[~((data[columns] < (Q1 - 1.5 * IQR)) |(data[columns] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "new_len = data.shape[0]\n",
    "percentage = round((original_len - new_len) / original_len * 100, 2)\n",
    "\n",
    "print(\"percentage of rows removed: \" + str(percentage) + \"%\")\n",
    "\n",
    "# Rechecking the plots to see distribution after removal of outliers\n",
    "#\n",
    "for col in columns:\n",
    "    sns.boxplot(x = data[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Invalid Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will split the date columns as month and year to get more granular insights.\n",
    "#\n",
    "columns = ['issue_d', 'earliest_cr_line']\n",
    "\n",
    "print(\"Following are the new columns added:\")\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "for col in columns:\n",
    "    month_col = str(col) + \"_month\"\n",
    "    year_col = str(col) + \"_year\"\n",
    "\n",
    "    data[[month_col, year_col]] = data[col].str.split('-', expand = True)\n",
    "    data[year_col] = data[year_col].apply(lambda x: int(x) + 2000 if int(x) <= 24 else int(x) + 1900)\n",
    "    \n",
    "    print(month_col)\n",
    "    print(year_col)\n",
    "    \n",
    "# Drop the original columns\n",
    "data.drop(columns = columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting data types if necessary\n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables with more than 30-40 unique values are counted as numerical.\n",
    "# Else, categorical.\n",
    "\n",
    "# Variables where ordering their values does not make sense are Unordered Categorical.\n",
    "#\n",
    "unordered_categorical_cols = ['term', 'loan_status', 'addr_state', 'verification_status', 'issue_d_month',\n",
    "    'home_ownership', 'purpose',  'desc_given', 'total_rec_late_fee_given'\n",
    "]\n",
    "\n",
    "# Variables where ordering their values makes sense are Ordered Categorical.\n",
    "#\n",
    "ordered_categorical_cols = ['inq_last_6mths', 'pub_rec', 'pub_rec_bankruptcies', 'grade',  \n",
    "    'issue_d_year', 'emp_length', 'earliest_cr_line_year','earliest_cr_line_month'\n",
    "]\n",
    "\n",
    "numerical_cols = [\n",
    "    'loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti', 'revol_util', 'open_acc',\n",
    "    'total_acc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charged_off_df = data[data['loan_status'] == 'Charged Off']\n",
    "charged_off_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucketting Months to quarters\n",
    "def get_month_and_quarter(month):\n",
    "    # Dictionary to map month numbers to month names\n",
    "    month_dict = {\n",
    "        1: \"Jan\", 2: \"Feb\", 3: \"Mar\",\n",
    "        4: \"Apr\", 5: \"May\", 6: \"Jun\",\n",
    "        7: \"Jul\", 8: \"Aug\", 9: \"Sep\",\n",
    "        10: \"Oct\", 11: \"Nov\", 12: \"Dec\"\n",
    "    }\n",
    "    \n",
    "    # Determine the month name\n",
    "    month_name = month_dict.get(month, \"Invalid Month\")\n",
    "    \n",
    "    # Determine the quarter\n",
    "    if month in [1, 2, 3]:\n",
    "        return \"Q1\"\n",
    "    elif month in [4, 5, 6]:\n",
    "        return \"Q2\"\n",
    "    elif month in [7, 8, 9]:\n",
    "        return \"Q3\"\n",
    "    elif month in [10, 11, 12]:\n",
    "        return \"Q4\"\n",
    "    else:\n",
    "        return \"Invalid Month\"\n",
    "\n",
    "    return f\"Month: {month_name}, Quarter: {quarter}\"\n",
    "\n",
    "data['issue_q'] = data.apply(lambda x : get_month_and_quarter(x['issue_d_month']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['loan_amnt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucketting Loan Amount\n",
    "def bucket_loan_amnt(column):\n",
    "    if column <= 5000:\n",
    "        return '0 - 5K'  # 25% quartile\n",
    "    elif (column >5000) and (column <= 10000):\n",
    "        return '5K - 10K'      \n",
    "    elif (column >10000) and (column <= 15000):\n",
    "        return '10K - 15K'  \n",
    "    else:\n",
    "        return '15K - above' # 75% quartile\n",
    "    \n",
    "data['loan_amnt_b'] = data.apply(lambda x : bucket_loan_amnt(x['loan_amnt']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating Categories\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(y=data.loan_amnt,x=data.loan_amnt_b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['funded_amnt_inv'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucketing Annual Income\n",
    "def bucket_annual_inc(column):\n",
    "    if column <= 40000:\n",
    "        return '0 - 40k' # 25% quartile\n",
    "    elif (column >40000) and (column <= 50000):\n",
    "        return '40k - 50k'    \n",
    "    elif (column >50000) and (column <= 60000):\n",
    "        return '50k to 60k'\n",
    "    elif (column >60000) and (column <= 70000):\n",
    "        return '60k to 70k'\n",
    "    elif (column >70000) and (column <= 80000):\n",
    "        return '70k to 80k'\n",
    "    else:\n",
    "        return '80k - above' # 75% quartile\n",
    "\n",
    "data['annual_inc_b'] = data.apply(lambda x: bucket_annual_inc(x['annual_inc']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['int_rate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucketing interest rate\n",
    "def bucket_int_rate(column):\n",
    "    if column <= 9:\n",
    "        return 'Very Low' # 25% quartile\n",
    "    elif (column >9) and (column <= 11):\n",
    "        return 'Low'    \n",
    "    elif (column >11) and (column <= 13):\n",
    "        return 'Moderate'\n",
    "    elif (column >13) and (column <= 15):\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High' # 75% quartile\n",
    "    \n",
    "data['int_rate_b'] = data.apply(lambda x : bucket_int_rate(x.int_rate), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating Categories\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(y=data.int_rate,x=data.int_rate_b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Post Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing column info to analyse missing values, empty values in a column\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univeriate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column metadata used by functions below\n",
    "column_titles = {\n",
    "    'loan_amnt': 'Loan Amount',\n",
    "    'funded_amnt': 'Funded Amount',\n",
    "    'funded_amnt_inv': 'Funded Amount Investors',\n",
    "    'term': 'Loan Term',\n",
    "    'int_rate': 'Interest Rate',\n",
    "    'installment': 'Installment',\n",
    "    'grade': 'Grade',\n",
    "    'emp_length': 'Employment Length',\n",
    "    'home_ownership': 'Home Owner Status',\n",
    "    'annual_inc': 'Annuap Income', \n",
    "    'verification_status': 'Verification Status',\n",
    "    'issue_d': 'Issue Date',\n",
    "    'loan_status': 'Loan Status',\n",
    "    'purpose': 'Purpose of Loan',\n",
    "    'addr_state': 'State',\n",
    "    'dti': 'Debt To Income Ratio',\n",
    "    'pub_rec_bankruptcies': 'Bankruptcies Record',\n",
    "    'issue_d_year': 'Issue Year',\n",
    "    'issue_d_month': 'Issue Month',\n",
    "    'issue_q': 'Issue Quarter',\n",
    "    'loan_amnt_b': 'Loan Amount Bins',\n",
    "    'funded_amnt_inv_b': 'Investor Funded Bins',\n",
    "    'funded_amnt_b': 'Funded Amount Bins',\n",
    "    'annual_inc_b': 'Annual Income Bins',\n",
    "    'int_rate_b': 'Interest Rate Bins',\n",
    "    'dti_b': 'DTI Bins'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a dictionary of outliers which includes the inter quartile range, \n",
    "# lower and upper bound for a particular column.\n",
    "# Formulae used in this analysis\n",
    "# IQR = 75th Quartile - 25th Quartile\n",
    "# Lower Bound = 25th Quartile - 1.5 * IQR\n",
    "# Upper Bound = 75th Quartile + 1.5 * IQR\n",
    "\n",
    "iqr_multiplier = 1.5\n",
    "\n",
    "def get_iqr(df, column):\n",
    "    quar25 = df[column].quantile(0.25)\n",
    "    quar75 = df[column].quantile(0.75)\n",
    "    iqr = quar75 - quar25\n",
    "    lower = quar25 - iqr_multiplier * iqr\n",
    "    upper = quar75 + iqr_multiplier * iqr\n",
    "    return {'quartile1': quar25, 'quartile3': quar75, 'iqr': iqr, 'lower_bound': lower, 'upper_bound': upper}\n",
    "\n",
    "\n",
    "# The function treat outliers, prints a box plot for each column under consideration\n",
    "# Plot 1 = Before outlier treatment\n",
    "# Plot 2 = Post outlier treatment\n",
    "# Also prints statistics of how many rows and percentage of rows dropped\n",
    "def outlier_comparison(df, column):\n",
    "    # box plot before dropping outliers\n",
    "    fig, p = plt.subplots(1,2,figsize=(14, 3))\n",
    "    splot1 = sns.boxplot(df[column], ax=p[0], orient=\"h\")\n",
    "    splot1.set_title('Plot ['+ column + '] - Original')\n",
    "    new_df = df[df[column] < get_iqr(df, column)['upper_bound']]\n",
    "    # box plot after dropping outliers    \n",
    "    splot2 = sns.boxplot(new_df[column], ax=p[1])\n",
    "    splot2.set_title('Plot [' + column + '] - Post Outlier Treatment')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def drop_outlier(df, column):\n",
    "    old_rows = len(df)\n",
    "    new_df = df[df[column] < get_iqr(df, column)['upper_bound']]\n",
    "    new_rows = len(new_df)\n",
    "    print('Rows dropped: ', old_rows - new_rows)\n",
    "    print('Percentage rows dropped: ', round((old_rows - new_rows)/old_rows*100,2), \"%\")\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def calculate_charged_off_percentage(group):\n",
    "    total_count = len(group)\n",
    "    filtered_count = len(group[group['loan_status'] == 'Charged Off'])  # Apply the desired filter\n",
    "    percentage = filtered_count / total_count * 100\n",
    "    return percentage\n",
    "\n",
    "def charged_off_dist_plots(col, figsize = (8, 5), vertical = False):\n",
    "     # determine grid\n",
    "     rows = 1\n",
    "     cols = 2\n",
    " \n",
    "     if vertical:\n",
    "         rows = 2\n",
    "         cols = 1\n",
    " \n",
    "     # plot univariate distribution\n",
    "     fig, axes = plt.subplots(rows, cols, figsize = figsize)\n",
    " \n",
    "     # group by column\n",
    "     df_grouped = data.groupby(col).size().reset_index(name = 'total')\n",
    "     charged_off_df_grouped = charged_off_df.groupby(col).size().reset_index(name = 'charged off')\n",
    "     # merge two df groups into one\n",
    "     df_merged = pd.merge(df_grouped, charged_off_df_grouped, on = col, how = 'outer')\n",
    "     df_merged.fillna({'charged off': 0}, inplace=True)\n",
    "     #df_merged['charged off'].fillna(0, inplace = true)\n",
    "     df_merged = df_merged.sort_values(by = 'total')\n",
    "     # plot the dataframe\n",
    "     df_merged.plot(x = col, y = 'total', kind = 'bar', ax = axes[0], colormap = 'Paired')\n",
    "     df_merged.plot(x = col, y = 'charged off', kind = 'bar', ax = axes[0], stacked = True)\n",
    "     axes[0].set_title(\"count distribution for \" + col)\n",
    "     # plot % of distribution in each segment\n",
    "     grouped = data.groupby(col).apply(calculate_charged_off_percentage,include_groups=False).sort_values()\n",
    "     grouped.plot(kind = 'bar', ax = axes[1])\n",
    "     axes[1].set_title(\"Charged off % for \" + col)\n",
    "     axes[1].set_xlabel(col)\n",
    "     axes[1].set_ylabel('Percentage')\n",
    "     fig.tight_layout()\n",
    "\n",
    "def univariate_analysis(df, column):\n",
    "    fig, p = plt.subplots(1,2, figsize=(16, 4))\n",
    "    sns.histplot(df.loc[df[column].notnull(), column], kde=True, ax=p[0])\n",
    "    sns.boxplot(x=column, data=df, ax=p[1])\n",
    "    p[0].set_xlabel(column_titles[column])\n",
    "    p[1].set_xlabel(column_titles[column])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate analysis of columns against loan_status and calculate the ratio of Charge Offs\n",
    "def analysis_vs_loan_status(df, col):\n",
    "    fig, p = plt.subplts(1,2, figsize=(16, 4))\n",
    "    splt = sns.countplt(df[col], ax=p[0])\n",
    "    splt.set_xticklabels(splt.get_xticklabels(), rotation=90);\n",
    "    p[0].set_title('['+ col + '] - loan_status=all')\n",
    "    cross_tab = pd.crosstab(df[col], df['loan_status'], normalize='index')\n",
    "    cross_tab.plt.bar(ax=p[1], stacked=True)\n",
    "    p[1].set_title('['+ col + '] - Stacked')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def continious_column_analysis(df, column):\n",
    "    f, (ax1, ax2) = plt.subplts(nrows=1, ncols=2, figsize=(16,4))\n",
    "    sns.distplt(df.loc[df[column].notnull(), column], kde=True, hist=True, ax=ax1)\n",
    "    sns.boxplt(x=column, y='loan_status', data=df, ax=ax2)\n",
    "    ax1.set_xlabel(column_titles[column])\n",
    "    ax2.set_xlabel(column_titles[column] + 'by Loan Status')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # return group by dataframe for display comparison\n",
    "    return df.groupby('loan_status')[column].describe()\n",
    "\n",
    "def comparison_loan_status(df, column):\n",
    "    df.groupby('loan_status')[column].value_counts().unstack().plt(kind='bar', figsize=[16,4])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def ratio_wise(df, column):\n",
    "    rw = df.pivot_table(index=column, columns='loan_status', values='loan_amnt', aggfunc=len).reset_index()\n",
    "    rw['total'] = rw['Charged Off'] + rw['Fully Paid']\n",
    "    rw['charge_off_ratio'] = round(rw['Charged Off'] / rw['total'] * 100)\n",
    "    rw.sort_values(by='total', ascending=False)\n",
    "    return rw\n",
    "\n",
    "def ratio_wise_plot(df, column, invert=False):\n",
    "    plt.figure(figsize=[10,4])\n",
    "    plt.title('Charged Off : ' + column_titles[column])\n",
    "    rw = ratio_wise(df, column)\n",
    "    if invert:\n",
    "        sns.barplot(x=rw['charge_off_ratio'], y=rw[column],data=df)\n",
    "    else:\n",
    "        sns.barplot(x=rw[column],y=rw['charge_off_ratio'],data=df)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return rw\n",
    "\n",
    "def series_plt(df, column, hue=None, annot=1):\n",
    "        temp = pd.Series()\n",
    "        fig, ax = plt.subplots(figsize=(20,14))\n",
    "        width = len(df[column].unique()) + 6 + 4 * len(temp.unique())\n",
    "        fig.set_size_inches(width , 7)\n",
    "        ax = sns.countplot(data = df, x=column, order=df[column].value_counts().index, hue=hue) \n",
    "        if annot == 1:\n",
    "            for p in ax.patches:\n",
    "                ax.annotate('{:1.1f}%'.format((p.get_height()*100)/float(len(df))), (p.get_x()+0.05, p.get_height()+20))  \n",
    "        elif annot == 2:\n",
    "            for p in ax.patches:\n",
    "                ax.annotate(p.get_height(), (p.get_x()+0.32, p.get_height()+20)) \n",
    "        del temp\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charged Off Distribution Plots Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UnOrdered Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['home_ownership','purpose','addr_state','term']\n",
    "\n",
    "for col in cols:\n",
    "    if col=='addr_state':\n",
    "        charged_off_dist_plots(col, figsize = (12, 12), vertical = True)\n",
    "    else:\n",
    "        charged_off_dist_plots(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "- Rent and Mortgage give almost similar business but Mortgage has less default percentage.\n",
    "- Small business are having high default rate.\n",
    "- Defaults rate for NY is less than 15% while CA goes above 15%.\n",
    "- There are almost thrice more loan takers for the term of 36 months with 15% less defaulters than 60 months term.\n",
    "- State CA has high number of loan applications.\n",
    "\n",
    "**Conclusion**:\n",
    "- Mortgage seems profitable.\n",
    "- Avoid giving loan to small businesses.\n",
    "- NY is a better state for profitability than CA. AK, NV, SD, TN states should be avoided to issue loans due to very high default rate.\n",
    "- April has highest default percentage while giving least customers.\n",
    "- Giving out loan for a term of 36 months seems far more profitable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordered Categorical Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ordered_categorical_cols:\n",
    "    if col == 'sub_grade' or col == 'earliest_cr_line_year':\n",
    "        charged_off_dist_plots(col, vertical = True)\n",
    "    else:\n",
    "        charged_off_dist_plots(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "**Column: Inquiries in past 6 months**\n",
    "- There are large number of loan takers for which least number of inquiries are made.\n",
    "- Percentage of defaulters is high for higher number of inquiries.\n",
    "\n",
    "**Analysis:**\n",
    "- Very less number of defaulters where none or only one inquiry is made.\n",
    "\n",
    "**Column: Public records and Bankruptcies**\n",
    "- Almost 25% default rate where there is atleast 1 public record or recorded bankruptcies.\n",
    "\n",
    "**Analysis:**\n",
    "- Issue loans only to those with no public records or bankruptcies.\n",
    "\n",
    "**Column: Loan Grade**\n",
    "- As grade of loan increases, percentage of defaulters go higher.\n",
    "\n",
    "**Analysis:**\n",
    "- Do not issue loans of D E F G categories, they have over 20% default rate.\n",
    "\n",
    "**Column: Issue Year**\n",
    "- Highest default rate in 2007\n",
    "\n",
    "**Analysis:**\n",
    "- This would be due to the Global financial crises.\n",
    "\n",
    "**Column: Employement Length**\n",
    "- Highest default rate with length of 4 years.\n",
    "\n",
    "**Analysis:**\n",
    "- This would be due to high expenses in other factors in life such as marriage, house buying, car etc.\n",
    "\n",
    "**Column: Earliest Credit Line Year**\n",
    "- Charged Off % is high in 1965.\n",
    "\n",
    "**Column: Earliest Credit Line Month**\n",
    "- April has highest default percentage while giving least customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative_cols=['loan_amnt','dti','funded_amnt','installment','funded_amnt_inv','int_rate','annual_inc','grade']\n",
    "for col in quantitative_cols:\n",
    "    univariate_analysis(data,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights\n",
    "\n",
    "- Majority of the loan_amount is in the range of 5K to 14K\n",
    "- Majority of the fund_amount is in the range of 5K to 14K\n",
    "- Majority of the installments are in the range of 20 to 400\n",
    "- Majority of the fund_amount is in the range of 5K to 12K\n",
    "- Majority of the interest rate is  5-15%\n",
    "- Max interest rate is 22.5%\n",
    "- Majority of the income is in  4K & 60K\n",
    "- Max Annual income is 145000\n",
    "- Majority of the Loan applications fall under Grade-B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unordered Categorical Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered=['purpose','home_ownership','addr_state','term','loan_status']\n",
    "\n",
    "for col in unordered:\n",
    "    data[col].value_counts().plot.bar()\n",
    "    plt.show()\n",
    "\n",
    "#data['home_ownership'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordered Categorical Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ordered_categorical_cols:\n",
    "    data[col].value_counts().plot.bar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['annual_inc_b'].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univarite Analysis Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Demographics\n",
    "- Majority of the loan applicants are in the range of 0 - 40K annual income\n",
    "- Majority of the home owner status are in status of RENT and MORTGAGE\n",
    "- Highest loan applications are in the category of debt_consolidation\n",
    "- Majority of the employment length of the customers are 10+ years and then in the range of 0-2 years\n",
    "\n",
    "### Loan Demographics\n",
    "- Highest loan amount applications fall in the range of 5k to 10k\n",
    "- Majority of the interest rate is in the range of 5% to 16% going at the max to 22%\n",
    "- Majority of the installment amount is in the range of 20$ to 400$\n",
    "- Majority of the loan applications counts are in the term of 36 months\n",
    "- Majority of loan application counts fall under the catogory of Grade B\n",
    "\n",
    "### Time Based Analysis\n",
    "- Loan application counts are increasing year over year.\n",
    "\n",
    "### Inferences\n",
    "- The customer demographic data shows which segment of customers to target for highest volume of loan\n",
    "- Indicates more analysis is needed why other categories are not as high as other few\n",
    "- Indicates the LendingClub to be prepared with volume in Q4\n",
    "- Indicates the LendingClub to target customers in other quarters to increase sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing column info to analyse missing values, empty values in a column\n",
    "print(data.info())\n",
    "data.head()\n",
    "# Taking a data snapshot\n",
    "#data.to_csv('snapshot.loan.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis v/s Charged Off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall ratio of Charge Offs\n",
    "series_plt(data, 'term', 'loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first column\n",
    "#data = data.iloc[:, 1:]\n",
    "if 'Id' not in data.columns:\n",
    "    data['id'] = range(1, len(data) + 1)\n",
    "ratio_wise_plot(data, 'term')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- The volume of loans are in the category of term = 36\n",
    "- The overall percentage of Charge Off's is slightly higher in term = 36 (8%) as compared to term=60 (6%)\n",
    "- If we calculate the ratio of Charge Off's within a category\n",
    "    - **Charge Off**s ratio is for the term=60 is 25% which is much higher than term=36 (10%)\n",
    "    - **term=60 is the loan applications which require more scrutiny**\n",
    "- **Conclusion**\n",
    "    - Most of the applicants with term=60 potentially will have high Charge Offs\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall ratio of Charge Offs against the total\n",
    "series_plt(data, 'grade', 'loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The ratio of Charge Offs within the category total\n",
    "ratio_wise_plot(data, 'grade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- The Majority of *loan volume is in grade=B*\n",
    "- If we analyse the Charge Off Ratio within a category\n",
    "    - The highest percentage of **Charge Off**s are in the *grade=G*\n",
    "    - Highest cluster of **Charge Off**s are in the grades G,F (> 30%)\n",
    "    - The volume of Grade G is extremely low 158 thus it does not contribute to overall risk significantly\n",
    "- **Inferences**\n",
    "    - Highest risk of charge off's are in the grades of B and C\n",
    "    - Grade \"F\" and \"G\" have very high chances of charged off. The columes are low\n",
    "    - Grade \"A\" has very less chances of charged off.\n",
    "    - Probablity of charged off is increasing from \"A\" to \"G\"\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall ratio of Charge Offs against the total\n",
    "series_plt(data, 'home_ownership', 'loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The ratio of Charge Offs within the category total\n",
    "ratio_wise_plot(data, 'home_ownership') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- Overall highest Charge Off numbers are in the category of RENT and MORTGAGE\n",
    "- Within each home_ownership category the ratio of Charge Off's for Other is higher\n",
    "- **Conclusions**\n",
    "    - The home_ownership status of MORTGAGE and are at the highest risk of Charge Offs\n",
    "    - MORTGAGE status also has the highest range of loan amounts increasing the risk\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall ratio of Charge Offs against the total\n",
    "series_plt(data, 'addr_state', 'loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The ratio of Charge Offs within the category total\n",
    "ratio_wise_plot(data, 'addr_state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- Highest volume of loans is from CA and purely based on volumes the hoghest Charge Off's are from CA\n",
    "- Within each state NE and NV has the highest Charge Offs\n",
    "- NE has very low volume this cannot be considered\n",
    "- Loan applications from NV will have high risk\n",
    "- **Inferences**\n",
    "    - Loan applications from NV (Neveda) have high risk of Charge Offs\n",
    "    - NE has very high probablity of Charge Offs. Volume too low\n",
    "    - NV,CA and FL have high percentage of Charge Off's\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall ratio of Charge Offs against the total\n",
    "series_plt(data, 'pub_rec_bankruptcies', 'loan_status')\n",
    "## The ratio of Charge Offs within the category total\n",
    "ratio_wise_plot(data, 'pub_rec_bankruptcies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    " - Purely based on volumes the number of charge_offs are in the category of 0 (no bankruptcy record)\n",
    " - Looking at ratios within each category, customers having bankruptcy record has high charge_off ratio\n",
    " - **Conclusions**\n",
    "    - Customers having bankruptcy record are at high risk of CHarge Offs\n",
    "    - pub_rec_bankruptcies count 2 has even higher Charge Off ratio\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Variate Analysis of Derived Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annual Income Bucket (annual_inc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall ratio of Charge Offs against the total\n",
    "series_plt(data, 'annual_inc_b', 'loan_status')\n",
    "## The ratio of Charge Offs within the category total\n",
    "ratio_wise_plot(data, 'annual_inc_b')\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(y=data.loan_amnt,x=data.annual_inc_b)\n",
    "plt.show()\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(y=data.int_rate,x=data.annual_inc_b)\n",
    "plt.show()\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(y=data.dti,x=data.annual_inc_b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- Annual income range of 0-40K has the highest charge offs\n",
    "- Charge off ratio within the bucket of 0-40K have highest Charge Offs\n",
    "- **Conclusions**\n",
    "    - Income range of 0-40K have the highest risk\n",
    "    - Income range 80000+  has less chances of charged off.\n",
    "    - Increase in annual income charged off proportion decreases. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loan Amount vs Annual Income for Charged Off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = charged_off_df[\"loan_amnt\"], y = charged_off_df[\"annual_inc\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "Very high density of low income and low loan amount. Reason for this needs to be understood with other variables.\n",
    "\n",
    "**Conclusion:**\n",
    "- Avoid issuing low loan amounts to low income customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Amount Bucket (loan_amnt_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall ratio of Charge Offs against the total\n",
    "series_plt(data, 'loan_amnt_b', 'loan_status')\n",
    "## The ratio of Charge Offs within the category total\n",
    "ratio_wise_plot(data, 'loan_amnt_b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- Based on volume highest percentage of Charge Offs are in the category of 5K to 10k of loan_ammount\n",
    "- The Charge Off ratio of all the customer;s within the loan_amount of 15K and above is at the highest CHarge Off risk\n",
    "- **Inferences**\n",
    "    - Charge Off risk of loan amount 15K and above is at the highest risk\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical vs Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['term', 'verification_status', 'emp_length','home_ownership', 'purpose', 'pub_rec_bankruptcies', 'grade']\n",
    "\n",
    "numerical_cols = ['loan_amnt', 'int_rate', 'annual_inc']\n",
    "\n",
    "for c_col in categorical_cols:\n",
    "    for n_col in numerical_cols:\n",
    "        plt.xticks(rotation = 90)\n",
    "        sns.boxplot(x = charged_off_df[c_col], y = charged_off_df[n_col])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "For all defaulters:\n",
    "- 60 term have issued very high loan amounts compared to 36 term. While annual income of both categories is almost similar.\n",
    "- As employment duration increases, median for default loan amount also increases, despite the interest rate being quite similar for all.\n",
    "- Strange to see median annual income for employment duration 0-10 increases very gradually for defaulters.\n",
    "- Median Interest rate for Home Owner with Other is very low while their Loan Default Amount is higher than others.\n",
    "- Defaults median of Loan Amount, Interest rate, and Annual Income for the purpose of Renewable Energy is very low.\n",
    "- Interest Rates for Grade E, F, G are very high making loan defaults higher while having similar annual income.\n",
    "\n",
    "**Conclusion:**\n",
    "- Do not issue loans for 60 term when income is similar to 36 term.\n",
    "- Do not issue loans to customers with higher employment duration yet having lower income (less than 6).\n",
    "- Increase interest rates for Home Owner with Other category.\n",
    "- Do not issue E, F, G loans for customers having income less than 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical vs Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This plot is used to check if two columns have positive/negative or no relationship\n",
    "#\n",
    "sns.scatterplot(x = charged_off_df[\"loan_amnt\"], y = charged_off_df[\"int_rate\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "The density of defaulters is high when loan amount is between 2k-7k with interest rates ranging from 11-15%.\n",
    "\n",
    "**Conclusion**\n",
    "- For smaller loan amounts interest rates should be kept very high to avoid defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\n",
    "    'loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti', 'open_acc', 'total_acc'\n",
    "]\n",
    "\n",
    "sns.pairplot(charged_off_df[numerical_cols])\n",
    "plt.show()\n",
    "numerical_df = charged_off_df[numerical_cols]\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "sns.heatmap(numerical_df.corr(), annot = True, fmt = '.2f', cmap = \"YlOrBr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "For all defaulters,\n",
    "- Loan amount and Interest rate have correlation of only 0.29 which suggests interest rate can be increased for higher loan amounts.\n",
    "- Annual income and Loan Amount have 0.37 correlation. So give higher loans only for very high annual income customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical vs Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['term', 'verification_status', 'emp_length',\n",
    "    'home_ownership', 'purpose', 'pub_rec_bankruptcies', 'grade'\n",
    "]\n",
    "sns.catplot(x='term', y='emp_length', hue='home_ownership', data=charged_off_df, kind='bar')\n",
    "plt.show()\n",
    "\n",
    "sns.catplot(x='term', y='loan_amnt', hue='home_ownership', data=charged_off_df, kind='bar')\n",
    "plt.show()\n",
    "\n",
    "sns.catplot(x='term', y='emp_length', hue='pub_rec_bankruptcies', data=charged_off_df, kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights\n",
    "- For 60 Term, there are no defaulters when loan is for Home Ownership \"Other\" category while employment length is > 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
